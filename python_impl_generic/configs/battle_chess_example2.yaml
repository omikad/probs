name: 'Evaluate agents via battle, example for trained chess agent vs trained agent using tree search'
cmd: battle
env:
  name: mychess6x6
  n_max_episode_steps: 200
evaluate:
  evaluate_n_games: 100
  randomize_n_turns: 2    # Number of first turns to play randomly (helps to evaluate deterministic players)
infra:
  threads_cnt: 1
  device: gpu
player1:
  kind: q_player
  model:
    value:
      class: ValueModel66_v11
    self_learner:
      class: SelfLearningModel66_v11
    checkpoint: 'environments/mychess6x6_v11_checkpoint_20240822-132834.ckpt'
player2:
  kind: q_player_tree_search
  model:
    value:
      class: ValueModel66_v11
    self_learner:
      class: SelfLearningModel66_v11
    checkpoint: 'environments/mychess6x6_v11_checkpoint_20240822-132834.ckpt'
  action_time_budget: 1.0
  expand_tree_budget: 20000
  batch_size: 16